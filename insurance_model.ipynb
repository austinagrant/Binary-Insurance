{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tqdm as tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "# test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  Gender   Age  Driving_License  Region_Code  Previously_Insured  \\\n",
      "0   0       0  21.0                1         35.0                   0   \n",
      "1   1       0  43.0                1         28.0                   0   \n",
      "2   2       1  25.0                1         14.0                   1   \n",
      "3   3       1  35.0                1          1.0                   0   \n",
      "4   4       1  36.0                1         15.0                   1   \n",
      "\n",
      "   Vehicle_Age  Vehicle_Damage  Annual_Premium  Policy_Sales_Channel  Vintage  \\\n",
      "0            0               1         65101.0                 124.0    187.0   \n",
      "1            1               1         58911.0                  26.0    288.0   \n",
      "2            0               0         38043.0                 152.0    254.0   \n",
      "3            0               1          2630.0                 156.0     76.0   \n",
      "4            0               0         31951.0                 152.0    294.0   \n",
      "\n",
      "   Response  \n",
      "0         0  \n",
      "1         1  \n",
      "2         0  \n",
      "3         0  \n",
      "4         0  \n"
     ]
    }
   ],
   "source": [
    "print(train_data.head())\n",
    "# print(test_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_map = {\n",
    "    'Male' : 0,\n",
    "    'Female' : 1\n",
    "}\n",
    "vehical_age_map = {\n",
    "    '1-2 Year' : 0,\n",
    "    '> 2 Years' : 1,\n",
    "    '< 1 Year' : 0\n",
    "}\n",
    "vehical_damage_map = {\n",
    "    'Yes' : 1,\n",
    "    'No' : 0\n",
    "}\n",
    "def map_df(df):\n",
    "    df['Gender'] = df['Gender'].map(gender_map)\n",
    "    df['Vehicle_Age'] = df['Vehicle_Age'].map(vehical_age_map)\n",
    "    df['Vehicle_Damage'] = df['Vehicle_Damage'].map(vehical_damage_map)\n",
    "    df['Age'] = df['Age'].apply(lambda a: float(a))\n",
    "    df['Vintage'] = df['Vintage'].apply(lambda v: float(v))\n",
    "\n",
    "map_df(train_data)\n",
    "# map_df(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = train_data[['Gender', 'Age', 'Driving_License', 'Region_Code',\n",
    "       'Previously_Insured', 'Vehicle_Age', 'Vehicle_Damage', 'Annual_Premium',\n",
    "       'Policy_Sales_Channel', 'Vintage']]\n",
    "y = train_data['Response']\n",
    "nfeats = len(X.columns)\n",
    "# X_test = test_data[['Gender', 'Age', 'Driving_License', 'Region_Code',\n",
    "#        'Previously_Insured', 'Vehicle_Age', 'Vehicle_Damage', 'Annual_Premium',\n",
    "#        'Policy_Sales_Channel', 'Vintage']]\n",
    "# X_test[['Age', 'Region_Code', 'Annual_Premium',  'Policy_Sales_Channel', 'Vintage']] = scaler.fit_transform(X_test[['Age', 'Region_Code', 'Annual_Premium',  'Policy_Sales_Channel', 'Vintage']])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Insurance_Dataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y.values, dtype=torch.float32).unsqueeze(1)\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "CKPT_DIR = \"CKPT\"\n",
    "LR = 0.001\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Insurance_Dataset(X_train, y_train)\n",
    "test_dataset = Insurance_Dataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(nfeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Insurance_Model(nn.Module):\n",
    "    def __init__(self, nfeats):\n",
    "        super(Insurance_Model, self).__init__()\n",
    "        self.input_layer = nn.Linear(nfeats, 64)\n",
    "        self.lyr1 = nn.Linear(64, 32)\n",
    "        self.lyr2 = nn.Linear(32, 8)\n",
    "        self.lyr3 = nn.Linear(8, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.input_layer(x))\n",
    "        x = torch.relu(self.lyr1(x))\n",
    "        x = torch.relu(self.lyr2(x))\n",
    "        x = torch.sigmoid(self.lyr3(x))\n",
    "        return x\n",
    "    \n",
    "model = Insurance_Model(nfeats).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, optimizer, epoch):\n",
    "    loss_fn = nn.BCELoss()\n",
    "    model.train()\n",
    "    with tqdm.tqdm(dataloader, unit=\"batch\") as tbatch:\n",
    "        for X, y in tbatch:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    torch.save(\n",
    "        {\n",
    "            \"epoch\" : epoch,\n",
    "            \"model_state_dict\" : model.state_dict(),\n",
    "            \"optimizer_state_dict\" : optimizer.state_dict(),\n",
    "            \"loss\" : loss\n",
    "        },\n",
    "        f\"{CKPT_DIR}/ckpt{epoch}.pt\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, dataset_name):\n",
    "    loss_fn = nn.BCELoss()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float32).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(\n",
    "        f\"{dataset_name} Accuracy: {(100 * correct):>0,1f}% Avg loss: {test_loss:>6f}\\n\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_or_restore_model(nfeat):\n",
    "    model = Insurance_Model(nfeat)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "    checkpoints = [\n",
    "        CKPT_DIR + \"/\" + name\n",
    "        for name in os.listdir(CKPT_DIR)\n",
    "        if name[-1] == \"t\"\n",
    "    ]\n",
    "    if checkpoints:\n",
    "        latest_checkpoint = max(checkpoints, key=os.path.getctime)\n",
    "        print(\"Restoring from\", latest_checkpoint)\n",
    "        ckpt = torch.load(latest_checkpoint)\n",
    "        model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "        optimizer.load_state_dict(ckpt[\"optimizer_state_dict\"])\n",
    "        epoch = ckpt[\"epoch\"]\n",
    "        return model, optimizer, epoch+1\n",
    "    else: \n",
    "        print(\"Creating new model\")\n",
    "        return model, optimizer, 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new model\n",
      "\n",
      "Epoch 0\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 575240/575240 [28:10<00:00, 340.25batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model, optimizer, epoch_start = make_or_restore_model(nfeats)\n",
    "model.to(device)\n",
    "for e in range(epoch_start, EPOCHS):\n",
    "    print()\n",
    "    print(\"Epoch\", e)\n",
    "    print(\"-------\")\n",
    "    model.train()\n",
    "    train(train_loader, model, optimizer, e)\n",
    "    print()\n",
    "    model.eval()\n",
    "    test(train_loader, model, \"Train\")\n",
    "    test(test_loader, model, \"Test\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
